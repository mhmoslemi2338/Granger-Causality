{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a939fd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6\n",
       "0  0.0000  0.0063  0.0027  0.0054  0.0138  0.0043  0.0137\n",
       "1  0.0051  0.0000  0.0040  0.0252  0.0150  0.0216  0.0051\n",
       "2  0.0070  0.0056  0.0000  0.0065  0.0262  0.0044  0.0105\n",
       "3  0.0097  0.0334  0.0055  0.0000  0.0034  0.0085  0.0023\n",
       "4  0.0088  0.0039  0.0081  0.0072  0.0000  0.0016  0.0147\n",
       "5  0.0045  0.0084  0.0043  0.0138  0.0204  0.0000  0.0045\n",
       "6  0.0043  0.0129  0.0024  0.0058  0.0101  0.0069  0.0000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAY1klEQVR4nO3df5Bd5X3f8fcHCcn8JhYGyxJGSiTXAZLaoMrpmDiJGWFRYwtPYCxCDfWo3rY2qT2etpHbMQ6M3akmaVynpp6R+VFB7QhXLs0myIAdwA5pEZKwKEhY7SLjYWV+WECEgfBj9376xz3Cl9XdvXd373LOPft5ec7suc95ztnvLp6vnv2e5zxHtomIiOo6ouwAIiJiYknUEREVl0QdEVFxSdQRERWXRB0RUXFzZ/wbzFtUyWklq0759bJDGNeeF/eXHUJbp73pLWWH0Na/8FvLDmFcf+SflB1CW/9ap5UdQluX/PQbmu41Xj2wr+ucc+RJvzzt7/dGmPFEHRHxhmqMlh1BzyVRR0S9uFF2BD2XRB0R9dJIoo6IqDRnRB0RUXGjI2VH0HNJ1BFRL7mZGBFRcSl9RERUXG4mRkRUW24mRkRUXUbUEREVN/pq2RH0XBJ1RNRLSh8RERWX0kdERMXNxhG1pHcCa4BFRdN+YND2wzMZWETElNRwRD3hiwMk/QGwGRBwX7EJ+DNJ6yc4b0DSDkk7Go0XehlvRMSE3Hi1661fdBpRrwPOsP26n0jSnwC7gf/Q7iTbG4GNUN0XB0RETc22ETXQAN7Wpn1hcSwiolrc6H7rE50S9WeAv5L0HUkbi+024K+AT894dBERk9UY7X7rQNJqSXslDbUr90qaL+nm4vg2SUuK9pWSdhXbA5I+0u0125mw9GH7NknvAFby+puJ223Xb4mqiOh/PRopS5oDXAOsAoaB7ZIGbe9p6bYOeNb2MklrgQ3AR4GHgBW2RyQtBB6Q9BeAu7jmYTrO+nDzwfl7J/1TRkSUoXc16pXAkO19AJI205wB15pU1wB/WOxvAb4qSbZfbOnzJpoJuttrHqZT6SMior+MjnS9tc5QK7aBlistAh5r+TzMLyoLh/WxPQIcBBYASHqPpN3Ag8A/L453c83D5IGXiKiXSYyoW2eo9ZrtbcAZkn4V2CTpO1O9VhJ1RNRKD2+f7QdObfm8uGhr12dY0lzgBODp18fjhyU9D5zZ5TUPk9JHRNRLo9H9NrHtwHJJSyXNA9YCg2P6DAKXF/sXAXfadnHOXABJpwHvBB7t8pqHyYg6IuqlR7M+ihkbVwC3A3OA623vlnQ1sMP2IHAdcJOkIeAZmokX4BxgvaRXaT5z8knbBwDaXbNTLEnUEVEvPXwy0fZWYOuYtitb9l8CLm5z3k3ATd1es5Mk6oiol9GRsiPouSTqiKiXPno0vFtJ1BFRLzVclGnGE/U/eMs7ZvpbTMl3n/w/ZYcwrtPf/PayQ2jrts+cVnYIbd39xy927lSSO99/ZNkhtHX+D35adghtXdKLiyRRR0RUXEofEREVl5uJEREVl9JHRETFpfQREVFxGVFHRFRcEnVERMW5fu/TTqKOiHoZyayPiIhqy83EiIiKS406IqLiUqOOiKi4jKgjIiouiToioto82rOX21ZGEnVE1EsNR9RTfgu5pI9PcGxA0g5JO558oZrr3kZETbnR/dYnppyogavGO2B7o+0VtleccszbpvEtIiImqeHutz4xYelD0nivQRFwSu/DiYiYphqWPjrVqE8BPgA8O6ZdwP+akYgiIqZjFt5M/EvgWNu7xh6QdPdMBBQRMS01HFFPWKO2vc72PeMc+72ZCSkiYhp6WKOWtFrSXklDkta3OT5f0s3F8W2SlhTtqyTtlPRg8fX9LefcXVxzV7Gd3CmOTM+LiHrp0WwOSXOAa4BVwDCwXdKg7T0t3dYBz9peJmktsAH4KHAA+JDtn0o6E7gdWNRy3qW2d3Qby3RmfUREVE/vRtQrgSHb+2y/AmwG1ozpswbYVOxvAc6VJNs/tH1obvJu4ChJ86f6IyVRR0StuNHoemt95qPYBloutQh4rOXzMK8fFb+uj+0R4CCwYEyf3wXut/1yS9sNRdnj85LU6WdK6SMi6mUSsz5sbwQ2zlQoks6gWQ45r6X5Utv7JR0HfBv4GHDjRNfJiDoi6qV3pY/9wKktnxcXbW37SJoLnAA8XXxeDNwCXGb7kUMn2N5ffP058E2aJZYJJVFHRL00Gt1vE9sOLJe0VNI8YC0wOKbPIHB5sX8RcKdtSzoRuBVYb/tvDnWWNFfSScX+kcAFwEOdAknpIyLqpUePhtsekXQFzRkbc4Drbe+WdDWww/YgcB1wk6Qh4BmayRzgCmAZcKWkK4u284AXgNuLJD0H+B7w9U6xJFFHRL30cLEl21uBrWParmzZfwm4uM15XwS+OM5lz55sHEnUEVEvfbTYUrdmPFG/dc6xM/0tpuQ3Tz697BDG9ddP7encqQQX/edfKjuEtrb84a+UHcK4zrl6uOwQ2vpH899edggzxiOzb62PiIj+khF1RETF9dELAbqVRB0R9ZIRdUREtTmJOiKi4nIzMSKi4jKijoiouCTqiIhqs5OoIyKqLSPqiIiKS6KOiKg2j+SBl4iIaqtfnk6ijoh6yQMvERFVV8NE3fFVXJLeKelcSceOaV89c2FFRExRYxJbn5gwUUv6l8CfA78PPCRpTcvhfz/Bea+9gv3R53/Sm0gjIrrghrve+kWn0scngLNtPy9pCbBF0hLbXwE03kmtr2D/yNs/1D+/jYjoex6pX8rplKiPsP08gO1HJf02zWR9GhMk6oiI0vRRSaNbnWrUT0p616EPRdK+ADgJ+LUZjCsiYkrc6H7rF50S9WXAE60NtkdsXwa8b8aiioiYqhreTJyw9GF73Ddz2v6b3ocTETE9/TRS7lbH6XkREf3EI91vnUhaLWmvpCFJ69scny/p5uL4tmLSBZJWSdop6cHi6/tbzjm7aB+S9KeSOt7vS6KOiFrpVY1a0hzgGuB84HTgEkmnj+m2DnjW9jLgy8CGov0A8CHbvwZcDtzUcs7XaM6oW15sHZ9JSaKOiFrp4c3ElcCQ7X22XwE2A2vG9FkDbCr2twDnSpLtH9r+adG+GziqGH0vBI63fa+bC2ffCFzYKZAk6oioF6vrrfXhvGIbaLnSIuCxls/DRRvt+tgeAQ4CC8b0+V3gftsvF/1b7/21u+ZhstZHRNTKZG4mtj6cNxMknUGzHHLedK6TRB0RteJGz57F2w+c2vJ5cdHWrs+wpLnACcDTAJIWA7cAl9l+pKX/4g7XPExKHxFRK41Rdb11sB1YLmmppHnAWmBwTJ9BmjcLAS4C7rRtSScCtwLrW6cy234ceE7SbxSzPS6juZ7ShJKoI6JWenUzsag5XwHcDjwMfMv2bklXS/pw0e06YIGkIeCzwKEpfFcAy4ArJe0qtpOLY58ErgWGgEeA73T6mVL6iIha6WHpA9tbga1j2q5s2X8JuLjNeV8EvjjONXcAZ04mjiTqiKgV12/xvJlP1EuPOGamv8WUbLj/K2WHMK5V7xro3KkEdzzxQNkhtHXWF35WdgjjOufo08oOoa0bDlbzv2XbIegk9XJEXRUZUUdErXRxk7DvJFFHRK1kRB0RUXF2EnVERKXVcZnTJOqIqJVGRtQREdWW0kdERMVl1kdERMVl1kdERMWlRh0RUXGpUUdEVFzW+oiIqLiUPiIiKq4xG28mSloJ2Pb24lXpq4EfFeu0RkRUyqwbUUv6AnA+MFfSd4H3AHcB6yW92/aXxjlvABgAOPfNK/j1436lt1FHRIxjNt5MvAh4FzAfeAJYbPs5SX8MbAPaJurWN/t+dsnaGpb2I6KqZt2IGhixPQq8KOkR288B2P47STVc+iQi+l0dR4adEvUrko62/SJw9qFGSScASdQRUTmjjfq9s7tTon6f7ZcB7NctHngkv3hFekREZdRxBDlhoj6UpNu0HwAOzEhEERHTYGZfjToioq80alikTqKOiFpp1HBEXb+qe0TMakZdb51IWi1pr6QhSevbHJ8v6ebi+DZJS4r2BZLukvS8pK+OOefu4pq7iu3kTnFkRB0RtTLaoxG1pDnANcAqYBjYLmnQ9p6WbuuAZ20vk7QW2AB8FHgJ+DxwZrGNdantHd3GkhF1RNRKYxJbByuBIdv7bL8CbAbWjOmzBthU7G8BzpUk2y/Yvodmwp62JOqIqJXJJGpJA5J2tGwDLZdaBDzW8nm4aKNdH9sjwEFgQRdh3lCUPT4vqeOfACl9REStTGZ6XutyF2+gS23vl3Qc8G3gY8CNE52QEXVE1EpD3W8d7AdObfm8uGhr20fSXOAE4OmJLmp7f/H158A3aZZYJpREHRG10kBdbx1sB5ZLWippHrAWGBzTZ5BfPKV9EXCnPf47ZiTNlXRSsX8kcAHwUKdAUvqIiFoZ7dF1bI9IugK4HZgDXG97t6SrgR22B4HrgJskDQHP0EzmAEh6FDgemCfpQuA84CfA7UWSngN8D/h6p1hmPFG/0LNfW2+9+4zfKzuEcZ191Nj7FdVw0sKzO3cqwf98fGfZIYzrwEsHyw6hrRuOruZ/y15odL4317XiBSlbx7Rd2bL/EnDxOOcuGeeyk/7lZ0QdEbVSwyfIk6gjol5m3ep5ERH9pobvtk2ijoh66dUj5FWSRB0RtZIRdURExaVGHRFRcZn1ERFRcSl9RERUXEofEREVN5oRdUREtWVEHRFRcUnUEREVV8dZH5Nej1rShG8iiIgoUw9fHFAZE46oJY1dJFvA70g6EcD2h8c5bwAYAPjNN5/Frx73y9OPNCKiC7Ox9LEY2ANcS/MvCgErgP840Umt7yH7Z0suruNfIhFRUdVcAX96OpU+VgA7gX8HHLR9N/B3tr9v+/szHVxExGTNutKH7QbwZUn/vfj6ZKdzIiLKNBtLHwDYHgYulvRB4LmZDSkiYurqWGud1OjY9q3ArTMUS0TEtDVqmKpTxoiIWqnjzcQk6oiolVlbo46I6Bf9NJujW5N+MjEiosoauOutE0mrJe2VNCRpfZvj8yXdXBzfJmlJ0b5A0l2Snpf01THnnC3pweKcP5XU8Z+WJOqIqBVPYpuIpDnANcD5wOnAJZJOH9NtHfCs7WXAl4ENRftLwOeBf9Xm0l8DPgEsL7bVnX6mJOqIqJXGJLYOVgJDtvfZfgXYDKwZ02cNsKnY3wKcK0m2X7B9D82E/RpJC4Hjbd9r28CNwIWdAkmijohaGcVdbx0sAh5r+TxctLXtY3sEOAgs6HDN4Q7XPEwSdUTUymRG1JIGJO1o2QZKCntCmfUREbUymQdeWheQa2M/cGrL58VFW7s+w5LmAicAT0/wLfcX15nomofJiDoiaqVXNxOB7cBySUslzQPWAmOXfh4ELi/2LwLuLGrP7WOzHweek/QbxWyPy4A/7xTIjI+od778xEx/iylZedTizp1Ksquiv7M/4LSyQ2jra7+1rOwQxrXw+0Nlh9DWVccMd+5Ugg/14Bq9euDF9oikK4DbgTnA9bZ3S7oa2GF7ELgOuEnSEPAMzWQOgKRHgeOBeZIuBM6zvQf4JPBfgaOA7xTbhFL6iIha6eImYddsbwW2jmm7smX/JeDicc5dMk77DuDMycSRRB0RtZJFmSIiKq5+aTqJOiJqJiPqiIiKy+p5EREV54yoIyKqrZezPqoiiToiaiWlj4iIimuM/2Bg30qijohaqV+aTqKOiJrJ9LyIiIrLrI+IiIobme2JWtI5NF9P85DtO2YmpIiIqavjiHrC9agl3dey/wngq8BxwBfavZG3pe9rb0342YvVXLIzIuqph+9MrIxOLw44smV/AFhl+yrgPODS8U6yvdH2Ctsr3nL0W3sQZkREd2x3vfWLTqWPIyT9Es2ELts/A7D9gqSRGY8uImKSZuOsjxOAnYAAS1po+3FJxxZtERGVMuseIR/vDQU0yzsf6Xk0ERHTNBtH1G3ZfhH4cY9jiYiYtn6qPXcr86gjolb6aTZHt5KoI6JW6jiPOok6ImolNeqIiIobdf2KH0nUEVErdSx9dHoyMSKirzTsrrdOJK2WtFfSULtlMyTNl3RzcXybpCUtxz5XtO+V9IGW9kclPShpl6Qd3fxMGVFHRK30ajwtaQ5wDbAKGAa2Sxq0vael2zrgWdvLJK0FNgAflXQ6sBY4A3gb8D1J77A9Wpz3O7YPdBtLRtQRUSsN3PXWwUpgyPY+268Am4E1Y/qsATYV+1uAcyWpaN9s+2XbPwaGiutNSRJ1RNTKZBJ160qfxTbQcqlFwGMtn4eLNtr1sT0CHAQWdDjXwB2Sdo75fuNK6SMiamUysz5sbwQ2zlw0bZ1je7+kk4HvSvqR7R9MdMKMJ+qqzml878ibyg5hXHe8/Ldlh9DWxqOPLjuEtu7/f28rO4RxffCtx5UdQlu3PvHDskOYMT2c9bEfOLXl8+KirV2fYUlzaS5k9/RE59o+9PUpSbfQLIlMmKhT+oiIWunhetTbgeWSlkqaR/Pm4OCYPoPA5cX+RcCdbl54EFhbzApZCiwH7pN0jKTjACQdQ3Nt/4c6BZLSR0TUSq/+irc9IukK4HZgDnC97d2SrgZ22B4ErgNukjQEPEMzmVP0+xawBxgBPmV7VNIpwC3N+43MBb5p+7ZOsSRRR0St9HL1PNtbga1j2q5s2X8JuHicc78EfGlM2z7g7082jiTqiKiV0Rqun5dEHRG10s0Th/0miToiaqWOa30kUUdErWREHRFRcRlRR0RUXEbUEREVlxcHRERUXEofEREV54yoIyKqraoLwU3HhIsySXqPpOOL/aMkXSXpLyRtkHTCGxNiRET3ergoU2V0Wj3veuDFYv8rNJfw21C03TDeSa2LcR948YmeBBoR0Y0evuGlMjqVPo4o3loAsML2WcX+PZJ2jXdS62LcZy08p39+GxHR90Yb9atRdxpRPyTp48X+A5JWAEh6B/DqjEYWETEFnsT/+kWnRP1Pgd+S9AhwOvC/Je0Dvl4ci4iolDrWqCcsfdg+CPyT4obi0qL/sO0n34jgIiImq59qz93qanqe7eeAB2Y4loiIaeunkXK3Mo86ImqljjcTk6gjolZmbekjIqJfpPQREVFxWeY0IqLi+ml+dLeSqCOiVjKijoiouEYNlznt9GRiRERf6eWTiZJWS9oraUjS+jbH50u6uTi+TdKSlmOfK9r3SvpAt9dsJ4k6ImqlV4la0hzgGuB8mktoXCLp9DHd1gHP2l4GfJnm6qIU/dYCZwCrgf8iaU6X1zxMEnVE1IonsXWwEhiyvc/2K8BmYM2YPmuATcX+FuBcSSraN9t+2faPgaHiet1c8zAzXqO+//F71KtrSRoollCtnF7Gtq4XFylU9XeWuCavqrFVLa6RV/Z3nXMkDQADLU0bW36WRcBjLceGgfeMucRrfWyPSDoILCja7x1z7qJiv9M1D9NvI+qBzl1KU9XYEtfkVDUuqG5sVY2rI9sbba9o2SrzD06rfkvUERFvlP3AqS2fFxdtbftImkvzLVhPT3BuN9c8TBJ1RER724HlkpZKmkfz5uDgmD6DwOXF/kXAnW7epRwE1hazQpYCy4H7urzmYfptHnUl/ywpVDW2xDU5VY0LqhtbVeOalqLmfAVwOzAHuN72bklXAztsDwLXATdJGgKeoZl4Kfp9C9gDjACfsj0K0O6anWJRHRcwiYiok5Q+IiIqLok6IqLi+iZRT+WxyzeCpOslPSXpobJjOUTSqZLukrRH0m5Jny47pkMkvUnSfZIeKGK7quyYWhVPj/1Q0l+WHcshkh6V9KCkXZJ2lB3PIZJOlLRF0o8kPSzpH5YdU131RY26eOzy/wKraE4Q3w5cYntPqYEBkt4HPA/caPvMsuMBkLQQWGj7fknHATuBCyvy+xJwjO3nJR0J3AN82va9HU59Q0j6LLACON72BWXHA81EDaywfaDsWFpJ2gT8te1rixkMR9v+25LDqqV+GVFP6bHLN4LtH9C821sZth+3fX+x/3PgYX7xVFSp3PR88fHIYqvEaEHSYuCDwLVlx1J1kk4A3kdz1gO2X0mSnjn9kqjbPcpZicRTdcVqXu8GtpUcymuK8sIu4Cngu7arEtt/Av4NULV1Mg3cIWln8chzFSwFfgbcUJSKrpV0TNlB1VW/JOqYAknHAt8GPmP7ubLjOcT2qO130Xwqa6Wk0ktGki4AnrK9s+xY2jjH9lk0V1z7VFFuK9tc4Czga7bfDbwAVObeUd30S6Ke0mOXs1lR//028A3b/6PseNop/lS+i+YykGV7L/Dhoh68GXi/pP9WbkhNtvcXX58CbqFZCizbMDDc8tfQFpqJO2ZAvyTqKT12OVsVN+yuAx62/Sdlx9NK0lsknVjsH0XzBvGPSg0KsP0524ttL6H5/687bf/jksNC0jHFDWGK0sJ5QOkzjGw/ATwm6e8VTefSfAovZkBfPEI+3qOcJYcFgKQ/A34bOEnSMPAF29eVGxXvBT4GPFjUggH+re2t5YX0moXApmImzxHAt2xXZipcBZ0C3NL8t5e5wDdt31ZuSK/5feAbxeBpH/DxkuOprb6YnhcRMZv1S+kjImLWSqKOiKi4JOqIiIpLoo6IqLgk6oiIikuijoiouCTqiIiK+//E5BKzBnio/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsdata_to_var_torch import tsdata_to_var_torch\n",
    "from var_to_autocov_torch import var_to_autocov_torch\n",
    "from autocov_to_pwcgc_torch import autocov_to_pwcgc_torch\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv('X.csv',header=None)\n",
    "X  = np.array(X).T # X must be numpy array in shape of (num var, num rows)\n",
    "X = torch.tensor(X)\n",
    "\n",
    "p=3\n",
    "A, SIG, E = tsdata_to_var_torch(X, p)\n",
    "G= var_to_autocov_torch(A,SIG, q = 100)\n",
    "F = autocov_to_pwcgc_torch(G,SIG)\n",
    "F = np.array(F)\n",
    "\n",
    "np.fill_diagonal(F,0)\n",
    "sns.heatmap(F)\n",
    "pd.DataFrame(np.round(F,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2e145ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv('X.csv',header=None)\n",
    "X  = np.array(X)\n",
    "X = torch.tensor(X, requires_grad=True)\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.float64\n",
    "X = X.to(device=device, dtype=dtype)\n",
    "clamp_eps = 1e-12\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def laplacian_eigendecomp_from_data(\n",
    "    X,\n",
    "    normalized: bool = False,\n",
    "    keep_only_positive: bool = False,\n",
    "    clamp_eps: float = 1e-12,\n",
    "    device=None,\n",
    "    dtype=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a feature–feature graph from correlations, then compute Laplacian eigendecomposition.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    X : (N, D) tensor\n",
    "        Data matrix: N samples, D features.\n",
    "    normalized : bool\n",
    "        If False -> unnormalized Laplacian L = D - A.\n",
    "        If True  -> symmetric normalized Laplacian L = I - D^{-1/2} A D^{-1/2}.\n",
    "    keep_only_positive : bool\n",
    "        If True, negative correlations are clamped to 0 (standard nonnegative-edge Laplacian).\n",
    "        If False, A keeps signs (L may not be PSD).\n",
    "    clamp_eps : float\n",
    "        Numerical floor to avoid division by zero (stds, degrees).\n",
    "    device, dtype :\n",
    "        Optional overrides for output tensors.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    evals : (D,) tensor\n",
    "        Eigenvalues (ascending = low frequency first).\n",
    "    evecs : (D, D) tensor\n",
    "        Eigenvectors as columns (orthonormal).\n",
    "    A     : (D, D) tensor\n",
    "        Correlation-derived adjacency used (diag set to 0).\n",
    "    L     : (D, D) tensor\n",
    "        Laplacian actually diagonalized.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = X.device\n",
    "    if dtype is None:\n",
    "        dtype = X.dtype\n",
    "    X = X.to(device=device, dtype=dtype)\n",
    "\n",
    "    N, D = X.shape\n",
    "\n",
    "    # ----- 1) Correlation adjacency A (D x D) -----\n",
    "    # Center features\n",
    "    Xc = X - X.mean(dim=0, keepdim=True)                 # (N, D)\n",
    "    # Unbiased std (N-1), clamp to avoid divide-by-zero\n",
    "    std = Xc.std(dim=0, unbiased=True).clamp_min(clamp_eps)  # (D,)\n",
    "    # Covariance\n",
    "    cov = (Xc.T @ Xc) / max(N - 1, 1)                    # (D, D)\n",
    "    # Pearson correlation\n",
    "    A = cov / (std.unsqueeze(1) * std.unsqueeze(0))      # (D, D)\n",
    "    # Enforce symmetry + diag=1 (numerical hygiene)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    A.fill_diagonal_(1.0)\n",
    "\n",
    "    # Optionally drop negative edges for a standard nonnegative-weight graph\n",
    "    if keep_only_positive:\n",
    "        A = torch.clamp(A, min=0.0)\n",
    "\n",
    "    # Remove self-loops for adjacency (standard for Laplacian)\n",
    "    A = A.clone()\n",
    "    A.fill_diagonal_(0.0)\n",
    "\n",
    "    # ----- 2) Degrees -----\n",
    "    deg = torch.abs(A).sum(dim=1)                                   # (D,)\n",
    "    Dmat = torch.diag(deg)                               # (D, D)\n",
    "\n",
    "\n",
    "    # ----- 3) Laplacian -----\n",
    "    if not normalized:\n",
    "        # Unnormalized: L = D - A\n",
    "        L = Dmat - A\n",
    "\n",
    "    else:\n",
    "        # Symmetric normalized: L = I - D^{-1/2} A D^{-1/2}\n",
    "        d_safe = deg.clamp_min(clamp_eps)\n",
    "        Dm12 = torch.diag(1.0 / torch.sqrt(d_safe))      # (D, D)\n",
    "        L = torch.eye(D, device=device, dtype=dtype) - (Dm12 @ A @ Dm12)\n",
    "\n",
    "    # ----- 4) Eigen-decomposition (symmetric/Hermitian) -----\n",
    "    # torch.linalg.eigh assumes symmetry and returns ascending eigenvalues\n",
    "    evals, evecs = torch.linalg.eigh(L)\n",
    "\n",
    "    return evals, evecs, A, L\n",
    "\n",
    "\n",
    "\n",
    "def subspace_loss_principal_angles(U1, U2):\n",
    "    \"\"\"\n",
    "    U1, U2: (D, k) with orthonormal columns (e.g., first k Laplacian eigenvectors)\n",
    "    Returns: loss in [0, 1], and principal cosines (singular values) for inspection.\n",
    "e Grassmann (principal-angles) loss — a\n",
    "        \"\"\"\n",
    "    # Cross-gram: k x k\n",
    "    M = U1.T @ U2\n",
    "\n",
    "    # Principal cosines = singular values of M (all in [0,1])\n",
    "    s = torch.linalg.svdvals(M)  # (k,)\n",
    "\n",
    "    # Average sin^2(theta) = 1 - mean(cos^2(theta))\n",
    "    loss = 1.0 - (s**2).mean()\n",
    "    return loss, s  # s are cos(theta_i)\n",
    "\n",
    "# evals_n, U, A_n, L_n = laplacian_eigendecomp_from_data(X, normalized=False)\n",
    "# print(\"Normalized:   eigenvalues:\", evals_n)\n",
    "\n",
    "\n",
    "L = X.shape[0]\n",
    "\n",
    "\n",
    "chunks = []\n",
    "for i in range(5):\n",
    "    X_i = X[L//5 * i : L//5 * (i+1)]\n",
    "    chunks.append(X_i)\n",
    "\n",
    "# Stack along a new axis\n",
    "X = torch.stack(chunks, dim=0)\n",
    "\n",
    "\n",
    "# evals_n1, U1, A_n, L_n = laplacian_eigendecomp_from_data(X1, normalized=False)\n",
    "\n",
    "\n",
    "# X2 = X[L//2:]\n",
    "# evals_n2, U2, A_n, L_n = laplacian_eigendecomp_from_data(X2, normalized=False)\n",
    "\n",
    "# # k = 3 /\n",
    "# # U1= U1[:, -k:]  \n",
    "# # U2 = U2[:, -k:]  \n",
    "\n",
    "\n",
    "# loss , _ = subspace_loss_principal_angles(U1, U2)\n",
    "\n",
    "# loss.backward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5a7c9eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 144, 7])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "330d623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple, Literal\n",
    "\n",
    "@torch.no_grad()\n",
    "def _make_eye(B: int, D: int, device, dtype):\n",
    "    I = torch.eye(D, device=device, dtype=dtype)\n",
    "    return I.expand(B, D, D)\n",
    "\n",
    "def laplacian_eigendecomp_batched(\n",
    "    X: torch.Tensor,                         # (B, N, D)\n",
    "    normalized: bool = False,\n",
    "    keep_only_positive: bool = False,\n",
    "    clamp_eps: float = 1e-12,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Batched version of your function.\n",
    "    Returns:\n",
    "      evals: (B, D), evecs: (B, D, D) [evecs columns], A: (B, D, D), L: (B, D, D)\n",
    "    \"\"\"\n",
    "    B, N, D = X.shape\n",
    "    device, dtype = X.device, X.dtype\n",
    "    I = _make_eye(B, D, device, dtype)\n",
    "\n",
    "    # 1) Correlation adjacency per batch\n",
    "    Xc   = X - X.mean(dim=1, keepdim=True)                      # (B, N, D)\n",
    "    std  = Xc.std(dim=1, unbiased=True).clamp_min(clamp_eps)    # (B, D)\n",
    "    # Covariance: (Xc^T Xc) / (N-1)\n",
    "    cov  = torch.matmul(Xc.transpose(1, 2), Xc) / max(N - 1, 1) # (B, D, D)\n",
    "    A    = cov / (std.unsqueeze(-1) * std.unsqueeze(-2))        # (B, D, D)\n",
    "    A    = 0.5 * (A + A.transpose(-1, -2))                      # symmetrize\n",
    "    # set diag to 1.0, then remove self-loops for Laplacian adjacency\n",
    "    A    = A * (1 - I) + I\n",
    "    if keep_only_positive:\n",
    "        A = torch.clamp(A, min=0.0)\n",
    "    A = A * (1 - I)                                            # remove self loops\n",
    "\n",
    "    # 2) Degree\n",
    "    deg  = A.abs().sum(dim=-1)                                  # (B, D)\n",
    "    Dmat = torch.diag_embed(deg)                                # (B, D, D)\n",
    "\n",
    "    # 3) Laplacian\n",
    "    if not normalized:\n",
    "        L = Dmat - A                                            # (B, D, D)\n",
    "    else:\n",
    "        d_safe = deg.clamp_min(clamp_eps)\n",
    "        dinv2  = 1.0 / torch.sqrt(d_safe)                       # (B, D)\n",
    "        Dm12   = torch.diag_embed(dinv2)                        # (B, D, D)\n",
    "        L      = I - torch.matmul(torch.matmul(Dm12, A), Dm12)  # (B, D, D)\n",
    "\n",
    "    # 4) Eigendecomposition (batched, symmetric)\n",
    "    # torch.linalg.eigh supports batches; returns ascending eigenvalues\n",
    "    evals, evecs = torch.linalg.eigh(L)                         # (B, D), (B, D, D)\n",
    "    return evals, evecs, A, L\n",
    "\n",
    "def take_first_k_evecs(evecs: torch.Tensor, k: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    evecs: (B, D, D) with eigenvectors in columns (as from eigh).\n",
    "    Returns U: (B, D, k) the first k eigenvectors (low-frequency).\n",
    "    \"\"\"\n",
    "    return evecs[:, :, :k].contiguous()\n",
    "\n",
    "def subspace_loss_principal_angles_batched(\n",
    "    U1: torch.Tensor,      # (B, D, k) orthonormal columns\n",
    "    U2: torch.Tensor,      # (B, D, k) orthonormal columns\n",
    "    reduction: Literal[\"mean\", \"sum\", \"none\"] = \"mean\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Batched Grassmann loss: 1 - mean(cos^2 theta) per batch, where cosines are\n",
    "    singular values of U1^T U2. Returns:\n",
    "      loss: () if reduced, else (B,)\n",
    "      cosines: (B, k)\n",
    "    \"\"\"\n",
    "    # Cross-gram per batch: (B, k, k)\n",
    "    M = torch.einsum('bdk,bdm->bkm', U1, U2)\n",
    "    s = torch.linalg.svdvals(M)                  # (B, k), values in [0,1]\n",
    "    batch_loss = 1.0 - (s ** 2).mean(dim=-1)     # (B,)\n",
    "    if reduction == \"mean\":\n",
    "        return batch_loss.mean(), s\n",
    "    elif reduction == \"sum\":\n",
    "        return batch_loss.sum(), s\n",
    "    else:\n",
    "        return batch_loss, s\n",
    "\n",
    "# ---- Example wiring (no loops) ----\n",
    "# X1, X2 are (B, N, D) two datasets you want to compare the k-dim Laplacian subspaces for\n",
    "evals1, evecs1, A, L = laplacian_eigendecomp_batched(X, normalized=True)\n",
    "evals2, evecs2, *_ = laplacian_eigendecomp_batched(X, normalized=True)\n",
    "\n",
    "# U1 = take_first_k_evecs(evecs1, k)   # (B, D, k)\n",
    "# U2 = take_first_k_evecs(evecs2, k)   # (B, D, k)\n",
    "loss, cosines = subspace_loss_principal_angles_batched(evecs1, evecs2, reduction=\"mean\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ea2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793fc27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c18bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c423a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "08020c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace loss (principal angles): 1.1102230246251565e-16\n",
      "Projection loss: 1.1703751527203171e-30\n",
      "Vector-wise (after Procrustes) loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def subspace_loss_principal_angles(U1, U2):\n",
    "    \"\"\"\n",
    "    U1, U2: (D, k) with orthonormal columns (e.g., first k Laplacian eigenvectors)\n",
    "    Returns: loss in [0, 1], and principal cosines (singular values) for inspection.\n",
    "    \"\"\"\n",
    "    # Cross-gram: k x k\n",
    "    M = U1.T @ U2\n",
    "\n",
    "    # Principal cosines = singular values of M (all in [0,1])\n",
    "    s = torch.linalg.svdvals(M)  # (k,)\n",
    "\n",
    "    # Average sin^2(theta) = 1 - mean(cos^2(theta))\n",
    "    loss = 1.0 - (s**2).mean()\n",
    "    return loss, s  # s are cos(theta_i)\n",
    "\n",
    "\n",
    "def subspace_loss_projection(U1, U2):\n",
    "    P1 = U1 @ U1.T\n",
    "    P2 = U2 @ U2.T\n",
    "    fro2 = torch.linalg.matrix_norm(P1 - P2, ord='fro')**2\n",
    "    # Normalize by k to keep scale comparable across k\n",
    "    return (fro2 / U1.shape[1])\n",
    "\n",
    "def eigenvectorwise_loss_procrustes(U1, U2):\n",
    "    \"\"\"\n",
    "    Align U1 to U2 via an optimal orthogonal Q, then compare columns one-by-one.\n",
    "    \"\"\"\n",
    "    # Solve: max_Q trace((U1^T U2) Q), Q orthogonal -> Q = U V^T where (U,S,Vt) = SVD(U1^T U2)\n",
    "    M = U1.T @ U2\n",
    "    U, _, Vt = torch.linalg.svd(M)\n",
    "    Q = U @ Vt  # (k, k)\n",
    "    U1_aligned = U1 @ Q\n",
    "\n",
    "    # Column-wise cosine similarities (should be ~1 if perfectly aligned)\n",
    "    # diag of (U1_aligned^T U2) are the cosines after alignment\n",
    "    diag_cos = torch.diag(U1_aligned.T @ U2)\n",
    "    loss = 1.0 - diag_cos.mean().clamp(min=-1.0, max=1.0)\n",
    "    return loss, diag_cos\n",
    "\n",
    "\n",
    "loss_subspace, principal_cos = subspace_loss_principal_angles(U1, U2)\n",
    "print(\"Subspace loss (principal angles):\", float(loss_subspace))\n",
    "# print(\"Principal cosines:\", principal_cos.tolist())\n",
    "\n",
    "# Optional alternative:\n",
    "loss_proj = subspace_loss_projection(U1, U2)\n",
    "print(\"Projection loss:\", float(loss_proj))\n",
    "\n",
    "# Optional vector-wise view (after best rotation):\n",
    "loss_vecwise, diag_cos = eigenvectorwise_loss_procrustes(U1, U2)\n",
    "print(\"Vector-wise (after Procrustes) loss:\", float(loss_vecwise))\n",
    "# print(\"Aligned column cosines:\", diag_cos.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac36fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fe251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2724d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e5f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "00672805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   nan, 0.0063, 0.0027, 0.0054, 0.0138, 0.0043, 0.0137],\n",
       "       [0.0051,    nan, 0.004 , 0.0252, 0.015 , 0.0216, 0.0051],\n",
       "       [0.007 , 0.0056,    nan, 0.0065, 0.0262, 0.0044, 0.0105],\n",
       "       [0.0097, 0.0334, 0.0055,    nan, 0.0034, 0.0085, 0.0023],\n",
       "       [0.0088, 0.0039, 0.0081, 0.0072,    nan, 0.0016, 0.0147],\n",
       "       [0.0045, 0.0084, 0.0043, 0.0138, 0.0204,    nan, 0.0045],\n",
       "       [0.0043, 0.0129, 0.0024, 0.0058, 0.0101, 0.0069,    nan]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Tuple, Dict\n",
    "import torch\n",
    "\n",
    "def schur_torch(A1):\n",
    "    Q_total = torch.eye(A1.size()[0], dtype=A1.dtype, device=A1.device)\n",
    "    \n",
    "    T = A1.clone()\n",
    "\n",
    "    for _ in range(30000):\n",
    "        # 1. Perform QR decomposition on the current matrix\n",
    "        # We use torch.linalg.qr, as torch.qr is deprecated.\n",
    "        Q, R = torch.linalg.qr(T)\n",
    "        \n",
    "        # 2. Recombine as R @ Q\n",
    "        # This new matrix is similar to the original A\n",
    "        # and converges to the upper-triangular Schur form T.\n",
    "        T = R @ Q\n",
    "        \n",
    "        # 3. Accumulate the orthogonal transformations\n",
    "        Q_total = Q_total @ Q\n",
    "\n",
    "    return T, Q_total\n",
    "\n",
    "\n",
    "\n",
    "def _vecF(M: torch.Tensor) -> torch.Tensor:\n",
    "    # Fortran-style vec (stack columns)\n",
    "    return M.transpose(0, 1).contiguous().reshape(-1, 1)\n",
    "\n",
    "def _unvecF(v: torch.Tensor, n: int, m: int) -> torch.Tensor:\n",
    "    # Inverse of _vecF\n",
    "    return v.reshape(m, n).transpose(0, 1).contiguous()\n",
    "\n",
    "def lyapslv_torch(A: torch.Tensor, Q: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Solve discrete-time Lyapunov via real Schur:\n",
    "        X = A X A^T + Q\n",
    "    using the column-wise block back-substitution (as in your NumPy/Scipy code).\n",
    "\n",
    "    Args:\n",
    "        A: (n,n) real tensor\n",
    "        Q: (n,n) real tensor\n",
    "        schur_fn: callable returning (T, U) where A = U @ T @ U.T (real Schur)\n",
    "\n",
    "    Returns:\n",
    "        X: (n,n) real tensor\n",
    "    \"\"\"\n",
    "    device = A.device\n",
    "    dtype  = A.dtype\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Real Schur\n",
    "    T, U = schur_torch(A)  # both (n,n)\n",
    "\n",
    "    # Flip signs to make diag(U) >= 0 where possible\n",
    "    s = torch.sign(torch.real(torch.diag(U)))\n",
    "    s = torch.where(s == 0, torch.ones_like(s), s)\n",
    "    S = torch.diag(s)\n",
    "\n",
    "    U = U @ S\n",
    "    T = S.T @ T @ S  # S is ±1 diagonal so S.T==S\n",
    "\n",
    "    # Transform Q\n",
    "    Qs = -(U.T @ Q @ U)\n",
    "\n",
    "    Xs = torch.zeros((n, n), dtype=dtype, device=device)\n",
    "\n",
    "    j = n\n",
    "    # small tolerance to detect 2x2 blocks in quasi-upper-triangular T\n",
    "    tol = torch.finfo(dtype).eps * 10\n",
    "\n",
    "    while j > 0:\n",
    "        j1 = j\n",
    "        # detect 2x2 block if subdiagonal entry is (numerically) nonzero\n",
    "        if j == 1:\n",
    "            bsiz = 1\n",
    "        elif torch.abs(T[j-1, j-2]) > tol:\n",
    "            bsiz = 2\n",
    "            j = j - 1  # include the (j-1)-th column as part of this 2x2 block\n",
    "        else:\n",
    "            bsiz = 1\n",
    "\n",
    "        bsizn = bsiz * n\n",
    "\n",
    "        # Kronecker system: (kron(T_jj, T) - I) vec(X(:, j..j1)) = rhs\n",
    "        Tjj = T[j-1:j1, j-1:j1]                               # (bsiz, bsiz)\n",
    "        Ajj = torch.kron(Tjj, T) - torch.eye(bsizn, dtype=dtype, device=device)\n",
    "\n",
    "        rhs = _vecF(Qs[:, j-1:j1])                            # (bsizn, 1)\n",
    "\n",
    "        # Add coupling to already-computed columns (to the right)\n",
    "        if j1 < n:\n",
    "            add_term = T @ (Xs[:, j1:n] @ T[j-1:j1, j1:n].T)  # (n, bsiz)\n",
    "            rhs = rhs + _vecF(add_term)\n",
    "\n",
    "        v = -torch.linalg.solve(Ajj, rhs)                     # (bsizn, 1)\n",
    "\n",
    "        # Fill current column(s)\n",
    "        Xs[:, j-1] = v[:n, 0]\n",
    "        if bsiz == 2:\n",
    "            Xs[:, j1-1] = v[n:bsizn, 0]\n",
    "\n",
    "        j -= 1\n",
    "\n",
    "    # Transform back\n",
    "    X = U @ Xs @ U.T\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _torch_demean(X: torch.Tensor, normalize: bool = False):\n",
    "    \"\"\"\n",
    "    X: (n, m, N)\n",
    "    Demean across the 'sample' axis collectively over trials, i.e., per variable (row)\n",
    "    over all m*N samples. Matches MATLAB-style:\n",
    "       Y = X(:,:); Y = Y - mean(Y,2)*ones(1,N*m); reshape back.\n",
    "    \"\"\"\n",
    "    n, m, N = X.shape\n",
    "    Y = X.reshape(n, m * N)\n",
    "    mu = Y.mean(dim=1, keepdim=True)            # (n,1)\n",
    "    Y = Y - mu\n",
    "    if normalize:\n",
    "        # unbiased=False here (population std) to mirror common MATLAB behavior unless you want ddof=1\n",
    "        sd = Y.std(dim=1, keepdim=True, unbiased=False).clamp_min(1e-12)\n",
    "        Y = Y / sd\n",
    "    return Y.reshape(n, m, N)\n",
    "\n",
    "\n",
    "def _chol_with_jitter(S, max_tries=5, jitter_scale=1e-10):\n",
    "    \"\"\"\n",
    "    Robust Cholesky with trace-based jitter fallback.\n",
    "    \"\"\"\n",
    "    n = S.shape[-1]\n",
    "    trace_S = torch.trace(S).clamp_min(0.0)\n",
    "    jitter = 0.0\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            return torch.linalg.cholesky(S + jitter * torch.eye(n, dtype=S.dtype, device=S.device))\n",
    "        except RuntimeError:\n",
    "            # Increase jitter (geometric)\n",
    "            jitter = jitter_scale * (trace_S / max(n, 1)) * (10.0 if jitter > 0 else 1.0)\n",
    "            if jitter == 0.0:  # handle trace 0\n",
    "                jitter = jitter_scale\n",
    "    # Final attempt may still fail and raise, which is fine (surface the error)\n",
    "    return torch.linalg.cholesky(S + jitter * torch.eye(n, dtype=S.dtype, device=S.device))\n",
    "\n",
    "\n",
    "def tsdata_to_var_torch(X, p: int, dtype=torch.float64, device=None):\n",
    "\n",
    "    \"\"\"\n",
    "    PyTorch implementation of your tsdata_to_var.\n",
    "\n",
    "    Args:\n",
    "        X: array-like (n, m) or (n, m, N). If (n, m), a singleton trial dim is added.\n",
    "        p: VAR order\n",
    "        dtype: torch dtype (default float64 for stability)\n",
    "        device: torch device (inferred from X if torch.Tensor; else cpu)\n",
    "\n",
    "    Returns:\n",
    "        A: (n, n, p)  VAR coefficients (Torch tensor)\n",
    "        SIG: (n, n)   residual covariance (Torch tensor, unbiased)\n",
    "        E: (n, m-p, N) residuals (Torch tensor)\n",
    "    \"\"\"\n",
    "    # ---- ingest & shape ----\n",
    "    if isinstance(X, torch.Tensor):\n",
    "        if device is None:\n",
    "            device = X.device\n",
    "        X = X.to(dtype=dtype, device=device)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\") if device is None else device\n",
    "        X = torch.as_tensor(X, dtype=dtype, device=device)\n",
    "\n",
    "    if X.ndim == 2:\n",
    "        X = X.unsqueeze(-1)  # (n, m, 1)\n",
    "    elif X.ndim != 3:\n",
    "        raise ValueError(\"X must be (n, m) or (n, m, N)\")\n",
    "\n",
    "    n, m, N = X.shape\n",
    "    if p < 1 or p >= m:\n",
    "        raise ValueError(\"p must be >=1 and < m\")\n",
    "\n",
    "    # ---- demean (no normalize) ----\n",
    "    X = _torch_demean(X, normalize=False)\n",
    "\n",
    "    # Prebuild lagged design tensor XX: (n, p+1, m+p, N), with XX[:,k,k:k+m,:] = X\n",
    "    p1 = p + 1\n",
    "    XX = torch.zeros((n, p1, m + p, N), dtype=dtype, device=device)\n",
    "    for k in range(p1):\n",
    "        XX[:, k, k:k+m, :] = X\n",
    "\n",
    "    I = torch.eye(n, dtype=dtype, device=device)\n",
    "\n",
    "    # ---- Initial whitening using all samples across trials ----\n",
    "    # E0 is vec of X across trials/time in MATLAB 'F' sense. We can use C-order with consistent math:\n",
    "    E0 = X.reshape(n, N * m)  # (n, Nm)\n",
    "    EE = E0 @ E0.T            # (n, n)\n",
    "\n",
    "    L0 = _chol_with_jitter(EE)\n",
    "    IC = torch.linalg.inv(L0)\n",
    "\n",
    "    # ---- Allocate AR coefficient blocks ----\n",
    "    p1n = p1 * n\n",
    "    AF = torch.zeros((n, p1n), dtype=dtype, device=device)\n",
    "    AB = torch.zeros((n, p1n), dtype=dtype, device=device)\n",
    "\n",
    "    # k = 1 init\n",
    "    k = 1\n",
    "    kn = k * n\n",
    "    M = N * (m - k)  # current number of stacked samples per (EF, EB)\n",
    "\n",
    "    # index helpers (1-based in original; we’ll use 0-based with same shapes)\n",
    "    # kf: first kn cols; kb: last kn cols of the p1n block\n",
    "    kk = torch.arange(1, k+1, device=device)\n",
    "    kf = torch.arange(1, kn+1, device=device)\n",
    "    kb = torch.arange(p1n - kn+1, p1n+1, device=device)\n",
    "\n",
    "    # Place IC:\n",
    "    AF[:, kf-1] = IC\n",
    "    AB[:, kb-1] = IC\n",
    "\n",
    "\n",
    "    while k <= p:\n",
    "    # while k <= 1:\n",
    "\n",
    "        block_F = XX[:, kk-1, k:m, :]                      # (n, k, m-k, N)\n",
    "        result_F = block_F.permute(1, 0, 2, 3).contiguous().view(kn, M)\n",
    "        EF = AF[:, kf-1] @ result_F                       # (n, M)\n",
    "\n",
    "        block_B = XX[:, kk-1, k-1:m-1, :]                  # (n, k, m-k, N)\n",
    "        result_B = block_B.permute(1, 0, 2, 3).contiguous().view(kn, M)\n",
    "        EB = AB[:, kb-1] @ result_B                      # (n, M)\n",
    "\n",
    "\n",
    "        # return EF, EB\n",
    "        # R = (L_F \\ EF) * (L_B \\ EB)'\n",
    "        L_F = _chol_with_jitter(EF @ EF.T)\n",
    "        L_B = _chol_with_jitter(EB @ EB.T)\n",
    "        R = torch.linalg.solve(L_F, EF) @ torch.linalg.solve(L_B, EB).T  # (n,n)\n",
    "\n",
    "        # Update to next k\n",
    "        k += 1\n",
    "        kn = k * n\n",
    "        M = N * (m - k)\n",
    "        kk = torch.arange(1, k+1, device=device)\n",
    "        kf = torch.arange(1, kn+1, device=device)\n",
    "        kb = torch.arange(p1n-kn+1,p1n+1, device=device)\n",
    "\n",
    "\n",
    "\n",
    "        # kf_next = torch.arange(0, kn_next, device=device)\n",
    "        # kb_next = torch.arange(p1n - kn_next, p1n, device=device)\n",
    "\n",
    "        # Keep previous active blocks\n",
    "        AFPREV = AF[:, kf-1]  # first kn columns\n",
    "        ABPREV = AB[:, kb-1] # last kn columns\n",
    "\n",
    "        # AF(:,1:kn_next) = inv(chol(I - R R^T)) * (AFPREV - R * ABPREV)\n",
    "        # AB(:,end-kn_next+1:end) = inv(chol(I - R^T R)) * (ABPREV - R^T * AFPREV)\n",
    "        LF = _chol_with_jitter(I - R @ R.T)\n",
    "        LB = _chol_with_jitter(I - R.T @ R)\n",
    "\n",
    "        AF[:, kf-1] = torch.linalg.solve(LF, AFPREV - R @ ABPREV)\n",
    "        AB[:, kb-1] = torch.linalg.solve(LB, ABPREV - R.T @ AFPREV)\n",
    "\n",
    "    # Extract A0 and A\n",
    "    A0 = AF[:, :n]                              # (n,n)\n",
    "    # Solve A0 * X = AF[:, n:]  -> X = A0^{-1} AF[:, n:]\n",
    "    A_flat = torch.linalg.solve(A0, AF[:, n:])  # (n, p*n)\n",
    "\n",
    "    # Reshape to (n,n,p) with lag-major stacking (equivalent to MATLAB/NumPy order='F')\n",
    "    A_lags = []\n",
    "    for lag in range(p):\n",
    "        A_lags.append(A_flat[:, lag * n : (lag + 1) * n])  # (n,n)\n",
    "    A = -torch.stack(A_lags, dim=2)  # (n,n,p)\n",
    "\n",
    "    # Residuals from the last EF step (whitened AF applied to data at order p)\n",
    "    # But we need residuals in the original (not whitened by A0): E = A0^{-1} * EF_last\n",
    "\n",
    "    E = torch.linalg.solve(A0, EF)  # (n, last_M)\n",
    "\n",
    "    # Unbiased covariance SIG = (E E^T) / (M - 1)  with M corresponding to last_EF sample count\n",
    "    denom = max(M - 1, 1)\n",
    "    SIG = (E @ E.T) / denom\n",
    "\n",
    "    # Reshape E back to (n, m-p, N).\n",
    "    # We stacked columns as (time, trial) in C-order; cols=M = (m-p)*N\n",
    "    # Arrange to (n, m-p, N) with time-major second axis:\n",
    "    E = E.view(n, (m - p), N)\n",
    "\n",
    "    return A, (SIG), (E)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def var_to_autocov_torch(\n",
    "    A: torch.Tensor,\n",
    "    SIG: torch.Tensor,\n",
    "    error: float = 1e-3,\n",
    "    q: Optional[int] = None,\n",
    ") -> Tuple[Dict[str, torch.Tensor], torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Torch port of your NumPy snippet.\n",
    "    Returns (info, A1, SIG1) so you can keep going with the rest of your pipeline.\n",
    "      - A:   (n, n, p)\n",
    "      - SIG: (n, n)\n",
    "    \"\"\"\n",
    "\n",
    "    device = A.device\n",
    "    dtype  = A.dtype\n",
    "\n",
    "    acdectol = error\n",
    "\n",
    "    n, n1, p = A.shape\n",
    "    assert n == n1, \"A must be (n, n, p)\"\n",
    "    nn1, nn2 = SIG.shape\n",
    "    assert (nn1, nn2) == (n, n), \"SIG must be (n, n)\"\n",
    "\n",
    "    pn1 = (p - 1) * n\n",
    "    pn  = p * n\n",
    "\n",
    "    # --- info dict (torch tensors for NaNs on the right device) ---\n",
    "    info = {\n",
    "        \"rho\":       torch.tensor(float(\"nan\"), device=device),\n",
    "        \"iters\":     torch.tensor(float(\"nan\"), device=device),\n",
    "        \"acrelerr\":  torch.tensor(float(\"nan\"), device=device),\n",
    "        \"acminlags\": torch.tensor(float(\"nan\"), device=device),\n",
    "        \"aclags\":    torch.tensor(float(\"nan\"), device=device),\n",
    "    }\n",
    "\n",
    "    G = None  # placeholder, as in your snippet\n",
    "\n",
    "    # Build companion-like A1\n",
    "    # A_top: (n, p*n) by concatenating A[:,:,k] across columns\n",
    "    A_top = torch.cat([A[:, :, k] for k in range(p)], dim=1)  # (n, p*n)\n",
    "\n",
    "    if pn1 > 0:\n",
    "        # A_bottom: ((p-1)*n, p*n) = [I_(pn1), 0]\n",
    "        A_bottom = torch.cat(\n",
    "            [\n",
    "                torch.eye(pn1, dtype=dtype, device=device),\n",
    "                torch.zeros((pn1, n), dtype=dtype, device=device),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        A1 = torch.cat([A_top, A_bottom], dim=0)  # (p*n, p*n)\n",
    "    else:\n",
    "        # p == 1: companion reduces to A_top (n x n)\n",
    "        A1 = A_top\n",
    "\n",
    "    # Spectral radius: max |eig(A1)|\n",
    "    eigvals, _ = torch.linalg.eig(A1)  # complex dtype if needed\n",
    "    info[\"rho\"] = eigvals.abs().max().real  # real scalar tensor\n",
    "\n",
    "    # SIG1 block matrix:\n",
    "    # [[SIG,            0_(n x pn1)]\n",
    "    #  [0_(pn1 x n),    0_(pn1 x pn1)]]\n",
    "    SIG1 = torch.zeros((n + pn1, n + pn1), dtype=SIG.dtype, device=device)\n",
    "    SIG1[:n, :n] = SIG\n",
    "\n",
    "    G1 = lyapslv_torch(A1, -SIG1)\n",
    "\n",
    "    \n",
    "    acminlags = torch.ceil(torch.log(torch.tensor(acdectol, dtype=dtype, device=device))\n",
    "                           / torch.log(torch.tensor(float(info['rho']), dtype=dtype, device=device)))\n",
    "    info['acminlags'] = int(acminlags.item())\n",
    "    info['aclags'] = info['acminlags']\n",
    "\n",
    "    if q is None:\n",
    "        q = info['aclags']\n",
    "\n",
    "\n",
    "\n",
    "    # Ensure plain ints\n",
    "    q = int(q)\n",
    "    q1 = q + 1\n",
    "\n",
    "    # ---- Build G_part with Fortran-order semantics: reshape(G1[:n,:], (n,n,p), order='F')\n",
    "    # In MATLAB/NumPy(F), this corresponds to taking consecutive n-column blocks.\n",
    "    # G_part[:, :, k] = G1[:n, k*n:(k+1)*n]\n",
    "    blocks = [G1[:n, k*n:(k+1)*n] for k in range(p)]\n",
    "    G_part = torch.stack(blocks, dim=2)                         # (n, n, p)\n",
    "\n",
    "    # Pad to length q1 along the 3rd dim\n",
    "    if q1 - p > 0:\n",
    "        G_tail = torch.zeros((n, n, q1 - p), dtype=dtype, device=device)\n",
    "        G = torch.cat((G_part, G_tail), dim=2)                  # (n, n, q1)\n",
    "    else:\n",
    "        G = G_part[:, :, :q1]\n",
    "\n",
    "    # B = vstack( zeros(( (q1-p)*n, n )), G1[:, -n:] )\n",
    "    top_zeros = torch.zeros(((q1 - p) * n, n), dtype=dtype, device=device) if (q1 - p) > 0 \\\n",
    "                else torch.zeros((0, n), dtype=dtype, device=device)\n",
    "    B = torch.vstack((top_zeros, G1[:, -n:]))                   # ((q1)*n, n)\n",
    "\n",
    "    # A2d = reshape(A, (n, pn), order='F') i.e., concatenate A[:,:,k] along columns\n",
    "    A2d = torch.cat([A[:, :, k] for k in range(p)], dim=1)      # (n, pn)\n",
    "\n",
    "    # Main loop\n",
    "    for k in range(p, q + 1):\n",
    "        r = q1 - k\n",
    "        # G[:, :, k] = A2d @ B[r*n : r*n + pn, :]\n",
    "        G[:, :, k] = A2d @ B[r * n : r * n + pn, :]\n",
    "        # B[(r-1)*n : r*n, :] = G[:, :, k]\n",
    "        B[(r - 1) * n : r * n, :] = G[:, :, k]\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def autocov_to_var_torch(G: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    PyTorch version of autocov_to_var.\n",
    "\n",
    "    Args:\n",
    "        G (torch.Tensor): shape (n, n, q1)\n",
    "    Returns:\n",
    "        SIG (torch.Tensor): residual covariance (n, n)\n",
    "    \"\"\"\n",
    "\n",
    "    n, _, q1 = G.shape\n",
    "    q = q1 - 1\n",
    "    qn = q * n\n",
    "\n",
    "    G0 = G[:, :, 0]\n",
    "\n",
    "    GF = G[:, :, 1:].permute(0, 2, 1).reshape(n, qn).T\n",
    "    G_flipped = torch.flip(G[:, :, 1:], dims=[2])\n",
    "    GB = G_flipped.permute(1, 2, 0).contiguous().view(n, qn).t()\n",
    "\n",
    "\n",
    "\n",
    "    AF = torch.zeros((n, qn), dtype=G.dtype, device=G.device)\n",
    "    AB = torch.zeros((n, qn), dtype=G.dtype, device=G.device)\n",
    "\n",
    "    k = 1\n",
    "    r = q - k\n",
    "    kf = torch.arange(1, k * n+1, device=G.device)\n",
    "    kb = torch.arange(r * n+1, qn+1, device=G.device)\n",
    "\n",
    "    G0_inv = torch.linalg.inv(G0)\n",
    "\n",
    "    AF[:, kf-1] = GB[kb-1, :] @ G0_inv\n",
    "    AB[:, kb-1] = GF[kf-1, :] @ G0_inv\n",
    "\n",
    "    for k in range(2, q + 1):\n",
    "\n",
    "\n",
    "        res = GB[(r - 1) * n : r * n, :] - AF[:, kf-1] @ GB[kb-1, :]\n",
    "        res2 = G0 - AB[:, kb-1] @ GB[kb-1, :]\n",
    "        AAF = res @ torch.linalg.inv(res2)\n",
    "\n",
    "        res = GF[(k - 1) * n : k * n, :] - AB[:, kb-1] @ GF[kf-1, :]\n",
    "        res2 = G0 - AF[:, kf-1] @ GF[kf-1, :]\n",
    "        AAB = res @ torch.linalg.inv(res2)\n",
    "\n",
    "        AFPREV = AF[:, kf-1]\n",
    "        ABPREV = AB[:, kb-1]\n",
    "\n",
    "        r = q - k\n",
    "        kf = torch.arange(1, k * n+1, device=G.device)\n",
    "        kb = torch.arange(r * n+1, qn+1, device=G.device)\n",
    "\n",
    "        AF[:, kf-1] = torch.cat([AFPREV - AAF @ ABPREV, AAF], dim=1)\n",
    "        AB[:, kb-1] = torch.cat([AAB, ABPREV - AAB @ AFPREV], dim=1)\n",
    "\n",
    "    SIG = G0 - AF @ GF\n",
    "    return SIG\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def autocov_to_pwcgc_torch(G: torch.Tensor, SIG: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    PyTorch version of autocov_to_pwcgc.\n",
    "    \n",
    "    Args:\n",
    "        G (torch.Tensor): Autocovariance sequence of shape (n, n, q)\n",
    "        SIG (torch.Tensor): Residual covariance matrix of shape (n, n)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Pairwise conditional Granger causality matrix (n, n)\n",
    "    \"\"\"\n",
    "    device = G.device\n",
    "    dtype = G.dtype\n",
    "    n = G.shape[0]\n",
    "\n",
    "    F = torch.full((n, n), float('nan'), dtype=dtype, device=device)\n",
    "    LSIG = torch.log(torch.diag(SIG))\n",
    "\n",
    "    for j in range(n):\n",
    "        # Indices excluding j\n",
    "        jo = torch.cat((torch.arange(0, j, device=device), torch.arange(j + 1, n, device=device)))\n",
    "\n",
    "        # Sub-autocovariance sequence excluding variable j\n",
    "        G_sub = G[jo][:, jo, :]\n",
    "\n",
    "        # Compute submodel covariance\n",
    "        SIGj = (autocov_to_var_torch((G_sub)))\n",
    "        # SIGj = torch.tensor(autocov_to_var(np.array(G_sub)))\n",
    "        LSIGj = torch.log(torch.diag(SIGj))\n",
    "\n",
    "        # Fill F\n",
    "        for ii in range(len(jo)):\n",
    "            i = jo[ii]\n",
    "            F[i, j] = LSIGj[ii] - LSIG[i]\n",
    "\n",
    "    return F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_F(X,p):\n",
    "    p=3\n",
    "    A, SIG, E = tsdata_to_var_torch(X, p)\n",
    "    G= var_to_autocov_torch(A,SIG, q = 100)\n",
    "    F = autocov_to_pwcgc_torch(G,SIG)\n",
    "    return F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = pd.read_csv('X.csv',header=None)\n",
    "X  = np.array(X).T # X must be numpy array in shape of (num var, num rows)\n",
    "X = torch.tensor(X)\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# n, m, N, p = 3, 50, 1, 2\n",
    "# X = torch.randn(n, m, N, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "np.round(np.array(calc_F(X,3)),4)\n",
    "# loss.backward()   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ca26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db185a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb3970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdf7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1103, 0.1189, 0.1086, 0.1317, 0.1341, 0.1116],\n",
       "        [0.0512, 0.0000, 0.0490, 0.0881, 0.0643, 0.0804, 0.0754],\n",
       "        [0.1149, 0.1065, 0.0000, 0.1042, 0.1354, 0.1271, 0.1070],\n",
       "        [0.0682, 0.0687, 0.0645, 0.0000, 0.0637, 0.0692, 0.0548],\n",
       "        [0.2531, 0.2366, 0.2538, 0.2347, 0.0000, 0.2597, 0.2463],\n",
       "        [0.1887, 0.1884, 0.1873, 0.1888, 0.1998, 0.0000, 0.1989],\n",
       "        [0.0824, 0.0950, 0.0787, 0.0922, 0.1056, 0.0911, 0.0000]],\n",
       "       dtype=torch.float64, grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diff import pwcgc_differentiable\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = pd.read_csv('X.csv',header=None)\n",
    "\n",
    "X  = np.array(X)[:,:].T # X must be numpy array in shape of (num var, num rows)\n",
    "X = torch.tensor(X, requires_grad=True)\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# n, m, N, p = 3, 50, 1, 2\n",
    "# X = torch.randn(n, m, N, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "F = pwcgc_differentiable(X)\n",
    "# F\n",
    "def myloss(A):\n",
    "    return torch.mean(A)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([X.requires_grad_()], lr=1e-3)\n",
    "\n",
    "\n",
    "loss = myloss(F)\n",
    "loss.backward()\n",
    "# optimizer.step()\n",
    "# # loss.backward()   \n",
    "\n",
    "# G = torch.zeros((n, n, q+1), dtype=Y.dtype, device=Y.device)\n",
    "\n",
    "# for k in range(q + 1):\n",
    "#     print(k)\n",
    "#     Y_t = Y[k:]              # (T - k, n)\n",
    "#     Y_tk = Y[:T - k]         # (T - k, n)\n",
    "#     G[:, :, k] = (Y_t.t() @ Y_tk) / (T - k)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7e2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0011, -0.2576,  1.0730, -0.2077, -0.0351, -0.1516, -0.0687],\n",
       "        [-0.1941,  0.2652, -0.2128,  0.1475,  0.0234,  0.3743,  0.0214],\n",
       "        [ 1.0597, -0.2799,  1.1442, -0.2244, -0.0811, -0.1678, -0.0800],\n",
       "        [-0.1570,  0.1482, -0.1699,  0.1921,  0.0065, -0.1283, -0.0035],\n",
       "        [ 0.0359,  0.0311, -0.0087,  0.0108,  0.2481,  0.0610,  0.0366],\n",
       "        [-0.1201,  0.3772, -0.1351, -0.1283,  0.0539,  1.6022,  0.0608],\n",
       "        [-0.1338,  0.0437, -0.1486,  0.0180,  0.0323,  0.0618,  0.1158]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004949b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5eb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ba5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aa8140d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.68614066e+01, -7.21644966e-16,  7.11751676e-16,\n",
       "          1.00160924e-15, -3.11603612e-15],\n",
       "        [ 0.00000000e+00, -1.86140662e+00, -1.90179753e-15,\n",
       "         -1.23269302e-15, -3.11053346e-16],\n",
       "        [ 0.00000000e+00,  0.00000000e+00, -1.03165151e-15,\n",
       "         -5.03303099e-16, -6.04453992e-16],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -7.22408129e-17, -5.47795406e-16],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.26116454e-16]]),\n",
       " array([[-0.27147568,  0.72546602, -0.49743654, -0.30742949, -0.24092322],\n",
       "        [-0.35197777,  0.41965658,  0.73699575,  0.30580969, -0.2516301 ],\n",
       "        [-0.43247986,  0.11384714,  0.10730265, -0.20089553,  0.86494342],\n",
       "        [-0.51298195, -0.1919623 , -0.43584637,  0.71407995, -0.0113037 ],\n",
       "        [-0.59348403, -0.49777174,  0.08898451, -0.51156462, -0.36108641]]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg.lapack import dgees\n",
    "\n",
    "def schur_real_direct(a):\n",
    "    a1 = np.array(a, dtype=np.float64, order='F')\n",
    "\n",
    "    # Workspace query (ask LAPACK for optimal work size)\n",
    "    query = dgees(lambda x: None, a1, lwork=-1)\n",
    "    lwork = int(np.real(query[-2][0]))\n",
    "\n",
    "    # Actual computation\n",
    "    res = dgees(lambda x: None, a1, lwork=lwork, sort_t=0)\n",
    "\n",
    "    T = res[0]\n",
    "    Z = res[-3]\n",
    "\n",
    "    return T, Z\n",
    "\n",
    "a = [\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 3, 4, 5, 6],\n",
    "    [3, 4, 5, 6, 7],\n",
    "    [4, 5, 6, 7, 8],\n",
    "    [5, 6, 7, 8, 9]\n",
    "]\n",
    "\n",
    "\n",
    "schur_real_direct(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2be3d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fortran object>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gees = scipy.linalg.lapack.dgees\n",
    "gees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
